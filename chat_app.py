# chat_app.py

import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_ollama.llms import OllamaLLM
from langchain_community.vectorstores import FAISS
from langchain_ollama import OllamaEmbeddings
from data_processing import FAISS_INDEX_PATH

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª–µ–π (–æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
st.markdown("""
    <style>
    .stApp {
        background-color: #0E1117;
        color: #FFFFFF;
    }
    
    /* Chat Input Styling */
    .stChatInput input {
        background-color: #1E1E1E !important;
        color: #FFFFFF !important;
        border: 1px solid #3A3A3A !important;
    }
    
    /* User Message Styling */
    .stChatMessage[data-testid="stChatMessage"]:nth-child(odd) {
        background-color: #1E1E1E !important;
        border: 1px solid #3A3A3A !important;
        color: #E0E0E0 !important;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
    }
    
    /* Assistant Message Styling */
    .stChatMessage[data-testid="stChatMessage"]:nth-child(even) {
        background-color: #2A2A2A !important;
        border: 1px solid #404040 !important;
        color: #F0F0F0 !important;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
    }
    
    /* Avatar Styling */
    .stChatMessage .avatar {
        background-color: #00FFAA !important;
        color: #000000 !important;
    }
    
    /* Text Color Fix */
    .stChatMessage p, .stChatMessage div {
        color: #FFFFFF !important;
    }
    
    .stFileUploader {
        background-color: #1E1E1E;
        border: 1px solid #3A3A3A;
        border-radius: 5px;
        padding: 15px;
    }
    
    h1, h2, h3 {
        color: #00FFAA !important;
    }
    </style>
    """, unsafe_allow_html=True)

PROMPT_TEMPLATE = """
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å. 
–ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ, —Å–∫–∞–∂–∏, —á—Ç–æ –Ω–µ –∑–Ω–∞–µ—à—å. –ë—É–¥—å –∫—Ä–∞—Ç–∫–∏–º –∏ —Ñ–∞–∫—Ç–æ–ª–æ–≥–∏—á–Ω—ã–º (–º–∞–∫—Å–∏–º—É–º 3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è). –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

–í–æ–ø—Ä–æ—Å: {user_query} 
–ö–æ–Ω—Ç–µ–∫—Å—Ç: {document_context} 
–û—Ç–≤–µ—Ç:
"""

EMBEDDING_MODEL = OllamaEmbeddings(model="nomic-embed-text")
LANGUAGE_MODEL = OllamaLLM(model="llama2")

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ FAISS
vector_store = FAISS.load_local(FAISS_INDEX_PATH, EMBEDDING_MODEL, allow_dangerous_deserialization=True)

def find_related_documents(query):
    documents = vector_store.similarity_search(query)
    return documents

def generate_answer(user_query, context_documents):
    context_text = "\n\n".join([doc.page_content for doc in context_documents])
    conversation_prompt = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)
    response_chain = conversation_prompt | LANGUAGE_MODEL
    response = response_chain.invoke({"user_query": user_query, "document_context": context_text})
    return response

# UI Configuration
st.title("üìò RS.SCM AI")
st.markdown("### –¢–≤–æ–π –ê–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º")
st.markdown("---")

st.success("‚úÖ –î–æ–∫—É–º–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã! –ó–∞–¥–∞–≤–∞–π—Ç–µ —Å–≤–æ–∏ –≤–æ–ø—Ä–æ—Å—ã –Ω–∏–∂–µ.")

# –ß–∞—Ç
user_input = st.chat_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö...")

if user_input:
    with st.chat_message("user"):
        st.write(user_input)
    
    with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–æ–∫—É–º–µ–Ω—Ç—ã..."):
        relevant_docs = find_related_documents(user_input)
        ai_response = generate_answer(user_input, relevant_docs)
    
    with st.chat_message("assistant", avatar="ü§ñ"):
        st.write(ai_response)